{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c0a4a38a26227b4195c19b73ceaaa36ecf000b920c1df7e74e9db74cfbdd1517"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "#  1. Linear classifier for CIFAR10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train: (50000, 32, 32, 3)\ny_train: (50000, 1)\nx_test: (10000, 32, 32, 3)\ny_test: (10000, 1)\nClasses K: 10\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('x_test:',x_test.shape)\n",
    "print('y_test:',y_test.shape)\n",
    "\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "print('Classes K:',K)"
   ]
  },
  {
   "source": [
    "- np.unique - Returns the sorted unique elements of an array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:  (50000, 3072)\ny_train:  (50000, 10)\nx_test:  (10000, 3072)\ny_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K) \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train: ', x_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print('x_test: ',x_test.shape)\n",
    "print('y_test: ',y_test.shape)"
   ]
  },
  {
   "source": [
    "- np.mean - Compute the arithmetic mean along the specified axis\n",
    "- tf.keras.utils.to_categorical - converts a class vector (integers) to binary class matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = Ntr\n",
    "iterations = 300\n",
    "lr = 1.4e-2     #learning rate,alpha\n",
    "lr_decay= 0.999\n",
    "reg = 5e-6      #regularization parameter,lamda"
   ]
  },
  {
   "source": [
    "### Definitions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def Loss(y_pred,y,w1,w2=0):\n",
    "    batch_size = y_pred.shape[0]\n",
    "    loss = (1/batch_size)*(np.square(y-y_pred)).sum() + reg*(np.sum(w1*w1)+np.sum(w2*w2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy function\n",
    "def Accuracy(y_pred,y):\n",
    "    batch_size = y_pred.shape[0]\n",
    "    K = y_pred.shape[1]\n",
    "    acc = 1-(1/(batch_size*K))*(np.abs(np.argmax(y,axis=1)-np.argmax(y_pred,axis=1))).sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear classifier model\n",
    "def LinearCls(x_train,y_train,x_test,y_test,K,Din,lr,lr_decay,reg):\n",
    "    Ntr = x_train.shape[0]\n",
    "    Nte = x_test.shape[0]\n",
    "\n",
    "    std = 1e-5\n",
    "    w1 = std*np.random.randn(Din, K)\n",
    "    b1 = np.zeros(K)\n",
    "\n",
    "    loss_history = []\n",
    "    tst_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    seed = 0\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    for t in range(iterations):\n",
    "        indices = np.arange(Ntr)\n",
    "        rng.shuffle(indices)\n",
    "        x = x_train[indices]\n",
    "        y = y_train[indices]\n",
    "\n",
    "        #forward pass\n",
    "        y_pred = x.dot(w1)+b1\n",
    "        y_pred_tst = x_test.dot(w1)+b1\n",
    "\n",
    "        train_loss = Loss(y_pred,y,w1)\n",
    "        loss_history.append(train_loss)\n",
    "        test_loss = Loss(y_pred_tst,y_test,w1)\n",
    "        tst_loss_history.append(test_loss)\n",
    "        train_acc = Accuracy(y_pred,y)\n",
    "        train_acc_history.append(train_acc)\n",
    "        test_acc = Accuracy(y_pred_tst,y_test)\n",
    "        val_acc_history.append(test_acc)\n",
    "\n",
    "        if t%10==0:\n",
    "            print('iteration %d / %d: Train loss = %f , Test loss = %f , Train accuracy = %f , Test accuracy = %f' % (t,iterations,train_loss,test_loss,train_acc,test_acc))\n",
    "\n",
    "        # Backward pass\n",
    "        dy_pred = (1./batch_size)*2.0*(y_pred-y)  #partial derivative of L w.r.t. y_pred\n",
    "        dw1 = x.T.dot(dy_pred)+reg*w1\n",
    "        db1 = dy_pred.sum(axis=0)\n",
    "        w1-=lr*dw1\n",
    "        b1-=lr*db1\n",
    "        lr*=lr_decay\n",
    "    return w1,b1,loss_history,tst_loss_history,train_acc_history,val_acc_history"
   ]
  },
  {
   "source": [
    "- np.random.randn - Return a sample (or samples) from the “standard normal” distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 0 / 300: Train loss = 0.999974 , Test loss = 0.999972 , Train accuracy = 0.684562 , Test accuracy = 0.684560\n",
      "iteration 10 / 300: Train loss = 0.876638 , Test loss = 0.876235 , Train accuracy = 0.756504 , Test accuracy = 0.758080\n",
      "iteration 20 / 300: Train loss = 0.842541 , Test loss = 0.842416 , Train accuracy = 0.762656 , Test accuracy = 0.767580\n",
      "iteration 30 / 300: Train loss = 0.823616 , Test loss = 0.823713 , Train accuracy = 0.766486 , Test accuracy = 0.770610\n",
      "iteration 40 / 300: Train loss = 0.812389 , Test loss = 0.812705 , Train accuracy = 0.768694 , Test accuracy = 0.771570\n",
      "iteration 50 / 300: Train loss = 0.805426 , Test loss = 0.805968 , Train accuracy = 0.770366 , Test accuracy = 0.772850\n",
      "iteration 60 / 300: Train loss = 0.800905 , Test loss = 0.801677 , Train accuracy = 0.771572 , Test accuracy = 0.773350\n",
      "iteration 70 / 300: Train loss = 0.797821 , Test loss = 0.798822 , Train accuracy = 0.772698 , Test accuracy = 0.773570\n",
      "iteration 80 / 300: Train loss = 0.795605 , Test loss = 0.796832 , Train accuracy = 0.773804 , Test accuracy = 0.774260\n",
      "iteration 90 / 300: Train loss = 0.793930 , Test loss = 0.795379 , Train accuracy = 0.774366 , Test accuracy = 0.774210\n",
      "iteration 100 / 300: Train loss = 0.792605 , Test loss = 0.794268 , Train accuracy = 0.775004 , Test accuracy = 0.773900\n",
      "iteration 110 / 300: Train loss = 0.791515 , Test loss = 0.793386 , Train accuracy = 0.775328 , Test accuracy = 0.773690\n",
      "iteration 120 / 300: Train loss = 0.790589 , Test loss = 0.792661 , Train accuracy = 0.776118 , Test accuracy = 0.773180\n",
      "iteration 130 / 300: Train loss = 0.789785 , Test loss = 0.792049 , Train accuracy = 0.776576 , Test accuracy = 0.773470\n",
      "iteration 140 / 300: Train loss = 0.789072 , Test loss = 0.791522 , Train accuracy = 0.776988 , Test accuracy = 0.773700\n",
      "iteration 150 / 300: Train loss = 0.788432 , Test loss = 0.791061 , Train accuracy = 0.777252 , Test accuracy = 0.773500\n",
      "iteration 160 / 300: Train loss = 0.787851 , Test loss = 0.790653 , Train accuracy = 0.777338 , Test accuracy = 0.773680\n",
      "iteration 170 / 300: Train loss = 0.787318 , Test loss = 0.790287 , Train accuracy = 0.777736 , Test accuracy = 0.773520\n",
      "iteration 180 / 300: Train loss = 0.786828 , Test loss = 0.789958 , Train accuracy = 0.778074 , Test accuracy = 0.773610\n",
      "iteration 190 / 300: Train loss = 0.786374 , Test loss = 0.789660 , Train accuracy = 0.778292 , Test accuracy = 0.773200\n",
      "iteration 200 / 300: Train loss = 0.785951 , Test loss = 0.789388 , Train accuracy = 0.778518 , Test accuracy = 0.773150\n",
      "iteration 210 / 300: Train loss = 0.785557 , Test loss = 0.789140 , Train accuracy = 0.778630 , Test accuracy = 0.773560\n",
      "iteration 220 / 300: Train loss = 0.785187 , Test loss = 0.788912 , Train accuracy = 0.778838 , Test accuracy = 0.773930\n",
      "iteration 230 / 300: Train loss = 0.784840 , Test loss = 0.788702 , Train accuracy = 0.779012 , Test accuracy = 0.773620\n",
      "iteration 240 / 300: Train loss = 0.784512 , Test loss = 0.788508 , Train accuracy = 0.779216 , Test accuracy = 0.773880\n",
      "iteration 250 / 300: Train loss = 0.784203 , Test loss = 0.788329 , Train accuracy = 0.779422 , Test accuracy = 0.774210\n",
      "iteration 260 / 300: Train loss = 0.783910 , Test loss = 0.788162 , Train accuracy = 0.779584 , Test accuracy = 0.773980\n",
      "iteration 270 / 300: Train loss = 0.783632 , Test loss = 0.788008 , Train accuracy = 0.779726 , Test accuracy = 0.774020\n",
      "iteration 280 / 300: Train loss = 0.783368 , Test loss = 0.787864 , Train accuracy = 0.779720 , Test accuracy = 0.774250\n",
      "iteration 290 / 300: Train loss = 0.783117 , Test loss = 0.787729 , Train accuracy = 0.779980 , Test accuracy = 0.774110\n"
     ]
    }
   ],
   "source": [
    "w1,b1,loss_history,tst_loss_history,train_acc_history,val_acc_history = LinearCls(x_train,y_train,x_test,y_test,K,Din,lr,lr_decay,reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}